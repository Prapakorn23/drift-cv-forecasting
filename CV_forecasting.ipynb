{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71afc1fb",
   "metadata": {},
   "source": [
    "# LSTM + RNN + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b5690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected drift points at indices: [120, 420, 660, 1110, 1350, 1710, 1950, 2190]\n",
      "Total drift points found: 8\n",
      "\n",
      "==================================================\n",
      "Testing RNN Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training RNN...\n",
      "[Adaptive Fold 1] RMSE=0.3587, MAE=0.3541\n",
      "\n",
      "[Adaptive Fold 2] Training RNN...\n",
      "[Adaptive Fold 2] RMSE=1.4067, MAE=1.3836\n",
      "\n",
      "[Adaptive Fold 3] Training RNN...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E42C855760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Adaptive Fold 3] RMSE=7.7252, MAE=7.6478\n",
      "\n",
      "[Adaptive Fold 4] Training RNN...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001E42CB26020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[Adaptive Fold 4] RMSE=14.7024, MAE=13.8750\n",
      "\n",
      "[Baseline Fold 1] Training RNN...\n",
      "[Baseline Fold 1] RMSE=2.9215, MAE=2.5946\n",
      "\n",
      "[Baseline Fold 2] Training RNN...\n",
      "[Baseline Fold 2] RMSE=1.0615, MAE=0.9393\n",
      "\n",
      "[Baseline Fold 3] Training RNN...\n",
      "[Baseline Fold 3] RMSE=8.0098, MAE=6.8966\n",
      "\n",
      "[Baseline Fold 4] Training RNN...\n",
      "[Baseline Fold 4] RMSE=5.3486, MAE=4.0478\n",
      "\n",
      "[Baseline Fold 5] Training RNN...\n",
      "[Baseline Fold 5] RMSE=70.3174, MAE=59.6587\n",
      "\n",
      "==================================================\n",
      "Testing LSTM Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training LSTM...\n",
      "[Adaptive Fold 1] RMSE=0.5167, MAE=0.5002\n",
      "\n",
      "[Adaptive Fold 2] Training LSTM...\n",
      "[Adaptive Fold 2] RMSE=0.7270, MAE=0.6897\n",
      "\n",
      "[Adaptive Fold 3] Training LSTM...\n",
      "[Adaptive Fold 3] RMSE=7.7345, MAE=7.6889\n",
      "\n",
      "[Adaptive Fold 4] Training LSTM...\n",
      "[Adaptive Fold 4] RMSE=24.1448, MAE=23.7396\n",
      "\n",
      "[Baseline Fold 1] Training LSTM...\n",
      "[Baseline Fold 1] RMSE=2.8427, MAE=2.4851\n",
      "\n",
      "[Baseline Fold 2] Training LSTM...\n",
      "[Baseline Fold 2] RMSE=0.8630, MAE=0.7809\n",
      "\n",
      "[Baseline Fold 3] Training LSTM...\n",
      "[Baseline Fold 3] RMSE=7.6644, MAE=6.5796\n",
      "\n",
      "[Baseline Fold 4] Training LSTM...\n",
      "[Baseline Fold 4] RMSE=4.8265, MAE=3.8609\n",
      "\n",
      "[Baseline Fold 5] Training LSTM...\n",
      "[Baseline Fold 5] RMSE=69.3140, MAE=58.8836\n",
      "\n",
      "==================================================\n",
      "Testing GRU Model\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training GRU...\n",
      "[Adaptive Fold 1] RMSE=0.4503, MAE=0.4447\n",
      "\n",
      "[Adaptive Fold 2] Training GRU...\n",
      "[Adaptive Fold 2] RMSE=0.8095, MAE=0.7485\n",
      "\n",
      "[Adaptive Fold 3] Training GRU...\n",
      "[Adaptive Fold 3] RMSE=8.7996, MAE=8.7405\n",
      "\n",
      "[Adaptive Fold 4] Training GRU...\n",
      "[Adaptive Fold 4] RMSE=15.5794, MAE=14.8981\n",
      "\n",
      "[Baseline Fold 1] Training GRU...\n",
      "[Baseline Fold 1] RMSE=2.6968, MAE=2.3300\n",
      "\n",
      "[Baseline Fold 2] Training GRU...\n",
      "[Baseline Fold 2] RMSE=1.1221, MAE=0.9948\n",
      "\n",
      "[Baseline Fold 3] Training GRU...\n",
      "[Baseline Fold 3] RMSE=7.4663, MAE=6.4883\n",
      "\n",
      "[Baseline Fold 4] Training GRU...\n",
      "[Baseline Fold 4] RMSE=4.5347, MAE=3.2764\n",
      "\n",
      "[Baseline Fold 5] Training GRU...\n",
      "[Baseline Fold 5] RMSE=65.3999, MAE=54.9078\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "RNN Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 6.0483, Avg MAE: 5.8151\n",
      "Baseline CV - Avg RMSE: 17.5318, Avg MAE: 14.8274\n",
      "\n",
      "LSTM Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 8.2808, Avg MAE: 8.1546\n",
      "Baseline CV - Avg RMSE: 17.1021, Avg MAE: 14.5180\n",
      "\n",
      "GRU Results:\n",
      "------------------------------\n",
      "Adaptive CV - Avg RMSE: 6.4097, Avg MAE: 6.2079\n",
      "Baseline CV - Avg RMSE: 16.2439, Avg MAE: 13.5995\n",
      "\n",
      "Best Model: RNN\n",
      "\n",
      "==================================================\n",
      "INDIVIDUAL MODEL EXAMPLES\n",
      "==================================================\n",
      "\n",
      "--- RNN Example ---\n",
      "\n",
      "--- GRU Example ---\n",
      "\n",
      "--- LSTM Example ---\n",
      "Models created successfully!\n",
      "Use .fit(X_train, y_train) to train and .predict(X_test) to predict\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, mannwhitneyu\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Preprocess data\n",
    "df = pd.read_csv(\"nvidia_10yr_data.csv\", parse_dates=[\"Date\"])\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")\n",
    "df = df.sort_values(\"Date\")\n",
    "\n",
    "# Feature engineering\n",
    "df['Return'] = df['Close'].pct_change()\n",
    "df['Volatility'] = df['Close'].rolling(10).std()\n",
    "df['Price_Diff'] = df['High'] - df['Low']\n",
    "df['Volume_Log'] = np.log1p(df['Volume'])\n",
    "\n",
    "# Drop NaN หลัง rolling\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Return', 'Volatility', 'Price_Diff', 'Volume_Log']]\n",
    "y = df['Close']\n",
    "\n",
    "\n",
    "class SequenceGenerator:\n",
    "    \"\"\"\n",
    "    สร้าง sequence data สำหรับ RNN-based models\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length: int = 30):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        \n",
    "    def create_sequences(self, X: pd.DataFrame, y: pd.Series, fit_scalers: bool = True):\n",
    "        \"\"\"\n",
    "        สร้าง sequence data สำหรับ RNN-based models\n",
    "        \"\"\"\n",
    "        # Scale features\n",
    "        if fit_scalers:\n",
    "            X_scaled = self.scaler_X.fit_transform(X)\n",
    "            y_scaled = self.scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "        else:\n",
    "            X_scaled = self.scaler_X.transform(X)\n",
    "            y_scaled = self.scaler_y.transform(y.values.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Create sequences\n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(self.sequence_length, len(X_scaled)):\n",
    "            X_seq.append(X_scaled[i-self.sequence_length:i])\n",
    "            y_seq.append(y_scaled[i])\n",
    "        \n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "    \n",
    "    def inverse_transform_y(self, y_scaled):\n",
    "        \"\"\"\n",
    "        แปลงค่า y กลับเป็นสเกลเดิม\n",
    "        \"\"\"\n",
    "        return self.scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    "class RNNRegressor:\n",
    "    \"\"\"\n",
    "    Universal RNN Regressor ที่รองรับ RNN, LSTM, และ GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = 'LSTM', sequence_length: int = 30, \n",
    "                 units: int = 50, dropout_rate: float = 0.2, \n",
    "                 learning_rate: float = 0.001, epochs: int = 100, \n",
    "                 batch_size: int = 32, verbose: int = 0):\n",
    "        \n",
    "        self.model_type = model_type.upper()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "        self.seq_generator = SequenceGenerator(sequence_length)\n",
    "        \n",
    "        # ตรวจสอบว่า model_type ถูกต้อง\n",
    "        if self.model_type not in ['RNN', 'LSTM', 'GRU']:\n",
    "            raise ValueError(\"model_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
    "        \n",
    "    def _get_layer_type(self):\n",
    "        \"\"\"\n",
    "        เลือก layer type ตาม model_type\n",
    "        \"\"\"\n",
    "        if self.model_type == 'RNN':\n",
    "            return SimpleRNN\n",
    "        elif self.model_type == 'LSTM':\n",
    "            return LSTM\n",
    "        elif self.model_type == 'GRU':\n",
    "            return GRU\n",
    "        \n",
    "    def _build_model(self, input_shape):\n",
    "        \"\"\"\n",
    "        สร้างโมเดล RNN ตาม model_type\n",
    "        \"\"\"\n",
    "        LayerType = self._get_layer_type()\n",
    "        \n",
    "        model = Sequential([\n",
    "            LayerType(self.units, return_sequences=True, input_shape=input_shape),\n",
    "            Dropout(self.dropout_rate),\n",
    "            LayerType(self.units // 2, return_sequences=False),\n",
    "            Dropout(self.dropout_rate),\n",
    "            Dense(25, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Train RNN model\n",
    "        \"\"\"\n",
    "        # Create sequences\n",
    "        X_seq, y_seq = self.seq_generator.create_sequences(X, y, fit_scalers=True)\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            raise ValueError(\"Not enough data to create sequences\")\n",
    "        \n",
    "        # Build model\n",
    "        self.model = self._build_model((X_seq.shape[1], X_seq.shape[2]))\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(\n",
    "            X_seq, y_seq,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not fitted yet\")\n",
    "        \n",
    "        # Create sequences (don't fit scalers)\n",
    "        X_seq, _ = self.seq_generator.create_sequences(\n",
    "            X, pd.Series([0] * len(X)), fit_scalers=False\n",
    "        )\n",
    "        \n",
    "        if len(X_seq) == 0:\n",
    "            # Return predictions for available data points\n",
    "            return np.array([])\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_scaled = self.model.predict(X_seq, verbose=0)\n",
    "        \n",
    "        # Inverse transform\n",
    "        y_pred = self.seq_generator.inverse_transform_y(y_pred_scaled)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class DriftPointDetector:\n",
    "    \"\"\"\n",
    "    ตรวจจับจุดเกิด concept drift ในข้อมูล time series ด้วยการใช้\n",
    "    หลายวิธีทดสอบและป้องกันการจับ pattern ที่ผิดพลาด\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size: int = 120, threshold: float = 0.001, \n",
    "                 step_size: int = 30, min_effect_size: float = 0.3,\n",
    "                 stability_window: int = 60, confirmation_tests: int = 2):\n",
    "        self.window_size = window_size\n",
    "        self.threshold = threshold\n",
    "        self.step_size = step_size\n",
    "        self.min_effect_size = min_effect_size\n",
    "        self.stability_window = stability_window\n",
    "        self.confirmation_tests = confirmation_tests\n",
    "        self.drift_points_: List[int] = []\n",
    "\n",
    "    def _calculate_effect_size(self, window1: pd.Series, window2: pd.Series) -> float:\n",
    "        \"\"\"คำนวณขนาดผลกระทบ (Cohen's d)\"\"\"\n",
    "        mean1, mean2 = window1.mean(), window2.mean()\n",
    "        std1, std2 = window1.std(), window2.std()\n",
    "        \n",
    "        pooled_std = np.sqrt(((len(window1) - 1) * std1**2 + (len(window2) - 1) * std2**2) / \n",
    "                           (len(window1) + len(window2) - 2))\n",
    "        \n",
    "        if pooled_std == 0:\n",
    "            return 0\n",
    "        \n",
    "        return abs(mean1 - mean2) / pooled_std\n",
    "\n",
    "    def _test_multiple_statistics(self, window1: pd.DataFrame, window2: pd.DataFrame) -> Tuple[int, float]:\n",
    "        \"\"\"ทดสอบหลายวิธีเพื่อยืนยัน drift\"\"\"\n",
    "        passed_tests = 0\n",
    "        min_p_value = 1.0\n",
    "        \n",
    "        for col in window1.columns:\n",
    "            col_tests = 0\n",
    "            col_p_values = []\n",
    "            \n",
    "            # Test 1: Kolmogorov-Smirnov test\n",
    "            try:\n",
    "                stat, p_value = ks_2samp(window1[col], window2[col])\n",
    "                col_p_values.append(p_value)\n",
    "                if p_value < self.threshold:\n",
    "                    col_tests += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Test 2: Mann-Whitney U test\n",
    "            try:\n",
    "                stat, p_value = mannwhitneyu(window1[col], window2[col], alternative='two-sided')\n",
    "                col_p_values.append(p_value)\n",
    "                if p_value < self.threshold:\n",
    "                    col_tests += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Test 3: Effect size check\n",
    "            effect_size = self._calculate_effect_size(window1[col], window2[col])\n",
    "            if effect_size > self.min_effect_size:\n",
    "                col_tests += 1\n",
    "            \n",
    "            if col_p_values:\n",
    "                min_p_value = min(min_p_value, min(col_p_values))\n",
    "            \n",
    "            if col_tests >= self.confirmation_tests:\n",
    "                passed_tests += 1\n",
    "        \n",
    "        return passed_tests, min_p_value\n",
    "\n",
    "    def _check_stability_before_drift(self, X: pd.DataFrame, position: int) -> bool:\n",
    "        \"\"\"ตรวจสอบว่าช่วงก่อนหน้ามีเสถียรภาพหรือไม่\"\"\"\n",
    "        if position < self.stability_window + self.window_size:\n",
    "            return True\n",
    "        \n",
    "        stable_start = position - self.stability_window - self.window_size\n",
    "        stable_end = position - self.window_size\n",
    "        stable_window = X.iloc[stable_start:stable_end]\n",
    "        \n",
    "        mid_point = len(stable_window) // 2\n",
    "        stable_part1 = stable_window.iloc[:mid_point]\n",
    "        stable_part2 = stable_window.iloc[mid_point:]\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if len(stable_part1) > 0 and len(stable_part2) > 0:\n",
    "                try:\n",
    "                    stat, p_value = ks_2samp(stable_part1[col], stable_part2[col])\n",
    "                    if p_value < self.threshold * 10:\n",
    "                        return False\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _remove_pattern_drifts(self, drift_candidates: List[Tuple[int, float]]) -> List[int]:\n",
    "        \"\"\"กรองจุด drift ที่อาจเป็น pattern\"\"\"\n",
    "        if len(drift_candidates) < 3:\n",
    "            return [pos for pos, _ in drift_candidates]\n",
    "        \n",
    "        drift_candidates.sort(key=lambda x: x[0])\n",
    "        \n",
    "        intervals = []\n",
    "        for i in range(1, len(drift_candidates)):\n",
    "            interval = drift_candidates[i][0] - drift_candidates[i-1][0]\n",
    "            intervals.append(interval)\n",
    "        \n",
    "        filtered_drifts = []\n",
    "        if len(intervals) > 1:\n",
    "            interval_std = np.std(intervals)\n",
    "            interval_mean = np.mean(intervals)\n",
    "            \n",
    "            if interval_std / interval_mean < 0.3:\n",
    "                drift_candidates.sort(key=lambda x: x[1])\n",
    "                keep_count = max(1, len(drift_candidates) // 3)\n",
    "                filtered_drifts = [pos for pos, _ in drift_candidates[:keep_count]]\n",
    "            else:\n",
    "                filtered_drifts = [pos for pos, _ in drift_candidates]\n",
    "        else:\n",
    "            filtered_drifts = [pos for pos, _ in drift_candidates]\n",
    "        \n",
    "        final_drifts = []\n",
    "        min_distance = self.window_size * 2\n",
    "        \n",
    "        for pos in sorted(filtered_drifts):\n",
    "            if not final_drifts or pos - final_drifts[-1] >= min_distance:\n",
    "                final_drifts.append(pos)\n",
    "        \n",
    "        return final_drifts\n",
    "\n",
    "    def detect(self, X: pd.DataFrame) -> List[int]:\n",
    "        self.drift_points_ = []\n",
    "        n = len(X)\n",
    "        drift_candidates = []\n",
    "        \n",
    "        for i in range(self.window_size, n - self.window_size, self.step_size):\n",
    "            if not self._check_stability_before_drift(X, i):\n",
    "                continue\n",
    "            \n",
    "            window1 = X.iloc[i - self.window_size:i]\n",
    "            window2 = X.iloc[i:i + self.window_size]\n",
    "            \n",
    "            passed_tests, min_p_value = self._test_multiple_statistics(window1, window2)\n",
    "            \n",
    "            if passed_tests >= 1:\n",
    "                drift_candidates.append((i, min_p_value))\n",
    "        \n",
    "        self.drift_points_ = self._remove_pattern_drifts(drift_candidates)\n",
    "        \n",
    "        return self.drift_points_\n",
    "\n",
    "\n",
    "class AdaptiveFoldGenerator:\n",
    "    \"\"\"\n",
    "    สร้าง train/test folds โดยแบ่งตาม drift points ที่ตรวจจับได้\n",
    "    \"\"\"\n",
    "    def __init__(self, min_fold_size: int = 200, test_ratio: float = 0.2):\n",
    "        self.min_fold_size = min_fold_size\n",
    "        self.test_ratio = test_ratio\n",
    "\n",
    "    def split(self, X: pd.DataFrame, drift_points: List[int]) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        folds = []\n",
    "        points = [0] + drift_points + [len(X)]\n",
    "        \n",
    "        for i in range(len(points) - 1):\n",
    "            start, end = points[i], points[i + 1]\n",
    "            fold_length = end - start\n",
    "\n",
    "            if fold_length < self.min_fold_size:\n",
    "                continue\n",
    "\n",
    "            split = int(start + (1 - self.test_ratio) * fold_length)\n",
    "            train_idx = np.arange(start, split)\n",
    "            test_idx = np.arange(split, end)\n",
    "\n",
    "            # เพิ่มขนาดขั้นต่ำสำหรับ RNN models\n",
    "            if len(train_idx) > 100 and len(test_idx) > 50:\n",
    "                folds.append((train_idx, test_idx))\n",
    "        \n",
    "        return folds\n",
    "\n",
    "\n",
    "class DriftAdaptiveTimeSeriesCV:\n",
    "    \"\"\"\n",
    "    ทำ cross-validation โดยใช้ fold ที่แบ่งตาม drift points สำหรับ RNN models\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = 'LSTM', model_params: dict = None):\n",
    "        self.model_type = model_type.upper()\n",
    "        self.model_params = model_params or {\n",
    "            'sequence_length': 30,\n",
    "            'units': 50,\n",
    "            'dropout_rate': 0.3,\n",
    "            'learning_rate': 0.001,\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'verbose': 0\n",
    "        }\n",
    "\n",
    "    def run(self, X: pd.DataFrame, y: pd.Series, drift_points: List[int]) -> Tuple[List[float], List[float]]:\n",
    "        fold_gen = AdaptiveFoldGenerator()\n",
    "        metrics_rmse, metrics_mae = [], []\n",
    "\n",
    "        folds = fold_gen.split(X, drift_points)\n",
    "        if not folds:\n",
    "            print(\"Warning: No valid folds generated by AdaptiveFoldGenerator!\")\n",
    "            return [], []\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(folds):\n",
    "            print(f\"\\n[Adaptive Fold {i+1}] Training {self.model_type}...\")\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # สร้างโมเดล RNN ใหม่สำหรับแต่ละ fold\n",
    "            model = RNNRegressor(model_type=self.model_type, **self.model_params)\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Align predictions with actual values (เนื่องจาก sequence length)\n",
    "                if len(y_pred) > 0:\n",
    "                    y_test_aligned = y_test.iloc[model.seq_generator.sequence_length:]\n",
    "                    y_test_aligned = y_test_aligned.iloc[:len(y_pred)]\n",
    "                    \n",
    "                    rmse = np.sqrt(mean_squared_error(y_test_aligned, y_pred))\n",
    "                    mae = mean_absolute_error(y_test_aligned, y_pred)\n",
    "                    \n",
    "                    print(f\"[Adaptive Fold {i+1}] RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "                    \n",
    "                    metrics_rmse.append(rmse)\n",
    "                    metrics_mae.append(mae)\n",
    "                else:\n",
    "                    print(f\"[Adaptive Fold {i+1}] No predictions generated (insufficient data)\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Adaptive Fold {i+1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return metrics_rmse, metrics_mae\n",
    "\n",
    "\n",
    "class BaselineTimeSeriesCV:\n",
    "    \"\"\"\n",
    "    ทำ cross-validation แบบ TimeSeriesSplit ปกติ สำหรับ RNN models\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type: str = 'LSTM', model_params: dict = None, n_splits: int = 5):\n",
    "        self.model_type = model_type.upper()\n",
    "        self.model_params = model_params or {\n",
    "            'sequence_length': 30,\n",
    "            'units': 50,\n",
    "            'dropout_rate': 0.3,\n",
    "            'learning_rate': 0.001,\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'verbose': 0\n",
    "        }\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def run(self, X: pd.DataFrame, y: pd.Series) -> Tuple[List[float], List[float]]:\n",
    "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "        metrics_rmse, metrics_mae = [], []\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "            print(f\"\\n[Baseline Fold {i+1}] Training {self.model_type}...\")\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # สร้างโมเดล RNN ใหม่สำหรับแต่ละ fold\n",
    "            model = RNNRegressor(model_type=self.model_type, **self.model_params)\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                # Align predictions with actual values\n",
    "                if len(y_pred) > 0:\n",
    "                    y_test_aligned = y_test.iloc[model.seq_generator.sequence_length:]\n",
    "                    y_test_aligned = y_test_aligned.iloc[:len(y_pred)]\n",
    "                    \n",
    "                    rmse = np.sqrt(mean_squared_error(y_test_aligned, y_pred))\n",
    "                    mae = mean_absolute_error(y_test_aligned, y_pred)\n",
    "                    \n",
    "                    print(f\"[Baseline Fold {i+1}] RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "                    \n",
    "                    metrics_rmse.append(rmse)\n",
    "                    metrics_mae.append(mae)\n",
    "                else:\n",
    "                    print(f\"[Baseline Fold {i+1}] No predictions generated (insufficient data)\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Baseline Fold {i+1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return metrics_rmse, metrics_mae\n",
    "\n",
    "\n",
    "class ModelComparison:\n",
    "    \"\"\"\n",
    "    เปรียบเทียบประสิทธิภาพของ RNN, LSTM, และ GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, model_params: dict = None):\n",
    "        self.model_params = model_params or {\n",
    "            'sequence_length': 30,\n",
    "            'units': 50,\n",
    "            'dropout_rate': 0.3,\n",
    "            'learning_rate': 0.001,\n",
    "            'epochs': 50,\n",
    "            'batch_size': 32,\n",
    "            'verbose': 0\n",
    "        }\n",
    "        self.models = ['RNN', 'LSTM', 'GRU']\n",
    "        \n",
    "    def compare_models(self, X: pd.DataFrame, y: pd.Series, drift_points: List[int]):\n",
    "        \"\"\"\n",
    "        เปรียบเทียบทั้ง 3 โมเดลด้วย adaptive CV\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for model_type in self.models:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Testing {model_type} Model\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Adaptive CV\n",
    "            drift_cv = DriftAdaptiveTimeSeriesCV(model_type, self.model_params)\n",
    "            drift_rmse, drift_mae = drift_cv.run(X, y, drift_points)\n",
    "            \n",
    "            # Baseline CV\n",
    "            baseline_cv = BaselineTimeSeriesCV(model_type, self.model_params, n_splits=5)\n",
    "            base_rmse, base_mae = baseline_cv.run(X, y)\n",
    "            \n",
    "            results[model_type] = {\n",
    "                'adaptive_rmse': drift_rmse,\n",
    "                'adaptive_mae': drift_mae,\n",
    "                'baseline_rmse': base_rmse,\n",
    "                'baseline_mae': base_mae\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_summary(self, results: dict):\n",
    "        \"\"\"\n",
    "        พิมพ์สรุปผลลัพธ์การเปรียบเทียบ\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MODEL COMPARISON SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for model_type in self.models:\n",
    "            if model_type in results:\n",
    "                print(f\"\\n{model_type} Results:\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                # Adaptive results\n",
    "                if results[model_type]['adaptive_rmse'] and results[model_type]['adaptive_mae']:\n",
    "                    avg_rmse = np.mean(results[model_type]['adaptive_rmse'])\n",
    "                    avg_mae = np.mean(results[model_type]['adaptive_mae'])\n",
    "                    print(f\"Adaptive CV - Avg RMSE: {avg_rmse:.4f}, Avg MAE: {avg_mae:.4f}\")\n",
    "                else:\n",
    "                    print(\"Adaptive CV - No valid results\")\n",
    "                \n",
    "                # Baseline results\n",
    "                if results[model_type]['baseline_rmse'] and results[model_type]['baseline_mae']:\n",
    "                    avg_rmse = np.mean(results[model_type]['baseline_rmse'])\n",
    "                    avg_mae = np.mean(results[model_type]['baseline_mae'])\n",
    "                    print(f\"Baseline CV - Avg RMSE: {avg_rmse:.4f}, Avg MAE: {avg_mae:.4f}\")\n",
    "                else:\n",
    "                    print(\"Baseline CV - No valid results\")\n",
    "        \n",
    "        # หาโมเดลที่ดีที่สุด\n",
    "        best_model = self._find_best_model(results)\n",
    "        if best_model:\n",
    "            print(f\"\\nBest Model: {best_model}\")\n",
    "\n",
    "\n",
    "    def _find_best_model(self, results: dict):\n",
    "        \"\"\"\n",
    "        หาโมเดลที่ดีที่สุดจากผลลัพธ์\n",
    "        \"\"\"\n",
    "        best_model = None\n",
    "        best_score = float('inf')\n",
    "        \n",
    "        for model_type in self.models:\n",
    "            if model_type in results:\n",
    "                # ใช้ adaptive RMSE เป็นเกณฑ์\n",
    "                if results[model_type]['adaptive_rmse']:\n",
    "                    avg_rmse = np.mean(results[model_type]['adaptive_rmse'])\n",
    "                    if avg_rmse < best_score:\n",
    "                        best_score = avg_rmse\n",
    "                        best_model = model_type\n",
    "                # ถ้าไม่มี adaptive results ใช้ baseline\n",
    "                elif results[model_type]['baseline_rmse']:\n",
    "                    avg_rmse = np.mean(results[model_type]['baseline_rmse'])\n",
    "                    if avg_rmse < best_score:\n",
    "                        best_score = avg_rmse\n",
    "                        best_model = model_type\n",
    "        \n",
    "        return best_model\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# ตัวอย่างการใช้งาน\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Detect drift points\n",
    "    detector = DriftPointDetector(\n",
    "        window_size=120, \n",
    "        threshold=0.001, \n",
    "        step_size=30,\n",
    "        min_effect_size=0.3,\n",
    "        stability_window=60,\n",
    "        confirmation_tests=2\n",
    "    )\n",
    "    drift_points = detector.detect(X)\n",
    "    print(f\"Detected drift points at indices: {drift_points}\")\n",
    "    print(f\"Total drift points found: {len(drift_points)}\")\n",
    "\n",
    "    # 2) เปรียบเทียบโมเดลทั้ง 3 แบบ\n",
    "    model_params = {\n",
    "        'sequence_length': 30,\n",
    "        'units': 50,\n",
    "        'dropout_rate': 0.3,\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 30,  # ลดลงเพื่อความเร็วในการทดสอบ\n",
    "        'batch_size': 32,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    comparator = ModelComparison(model_params)\n",
    "    results = comparator.compare_models(X, y, drift_points)\n",
    "    comparator.print_summary(results)\n",
    "    \n",
    "    # 3) ตัวอย่างการใช้โมเดลแต่ละตัวแยกกัน\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INDIVIDUAL MODEL EXAMPLES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ตัวอย่างการใช้ RNN\n",
    "    print(\"\\n--- RNN Example ---\")\n",
    "    rnn_model = RNNRegressor(model_type='RNN', **model_params)\n",
    "    \n",
    "    # ตัวอย่างการใช้ GRU\n",
    "    print(\"\\n--- GRU Example ---\")\n",
    "    gru_model = RNNRegressor(model_type='GRU', **model_params)\n",
    "    \n",
    "    # ตัวอย่างการใช้ LSTM\n",
    "    print(\"\\n--- LSTM Example ---\")\n",
    "    lstm_model = RNNRegressor(model_type='LSTM', **model_params)\n",
    "    \n",
    "    print(\"Models created successfully!\")\n",
    "    print(\"Use .fit(X_train, y_train) to train and .predict(X_test) to predict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
