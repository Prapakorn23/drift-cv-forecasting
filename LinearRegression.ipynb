{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "135012b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected drift points at indices: [120, 420, 660, 1110, 1350, 1710, 1950, 2190]\n",
      "Total drift points found: 8\n",
      "\n",
      "==================================================\n",
      "Linear Regression Analysis\n",
      "==================================================\n",
      "\n",
      "[Adaptive Fold 1] Training Linear Regression...\n",
      "[Adaptive Fold 1] RMSE=0.5575, MAE=0.5353\n",
      "\n",
      "[Adaptive Fold 2] Training Linear Regression...\n",
      "[Adaptive Fold 2] RMSE=1.3440, MAE=1.2984\n",
      "\n",
      "[Adaptive Fold 3] Training Linear Regression...\n",
      "[Adaptive Fold 3] RMSE=1.2679, MAE=1.1673\n",
      "\n",
      "[Adaptive Fold 4] Training Linear Regression...\n",
      "[Adaptive Fold 4] RMSE=1.8223, MAE=1.6010\n",
      "\n",
      "[Adaptive Fold 5] Training Linear Regression...\n",
      "[Adaptive Fold 5] RMSE=5.4170, MAE=5.0177\n",
      "\n",
      "[Adaptive Fold 6] Training Linear Regression...\n",
      "[Adaptive Fold 6] RMSE=2.9093, MAE=2.4371\n",
      "\n",
      "[Adaptive Fold 7] Training Linear Regression...\n",
      "[Adaptive Fold 7] RMSE=11.2985, MAE=9.8716\n",
      "\n",
      "[Adaptive Fold 8] Training Linear Regression...\n",
      "[Adaptive Fold 8] RMSE=24.7924, MAE=22.5382\n",
      "\n",
      "[Baseline Fold 1] Training Linear Regression...\n",
      "[Baseline Fold 1] RMSE=1.7622, MAE=1.3741\n",
      "\n",
      "[Baseline Fold 2] Training Linear Regression...\n",
      "[Baseline Fold 2] RMSE=2.1970, MAE=1.6823\n",
      "\n",
      "[Baseline Fold 3] Training Linear Regression...\n",
      "[Baseline Fold 3] RMSE=4.7748, MAE=3.9555\n",
      "\n",
      "[Baseline Fold 4] Training Linear Regression...\n",
      "[Baseline Fold 4] RMSE=8.3381, MAE=6.0330\n",
      "\n",
      "[Baseline Fold 5] Training Linear Regression...\n",
      "[Baseline Fold 5] RMSE=32.6020, MAE=26.6973\n",
      "\n",
      "================================================================================\n",
      "LINEAR REGRESSION ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Linear Regression Results:\n",
      "----------------------------------------\n",
      "Adaptive CV:\n",
      "  - RMSE: 6.1761 ± 7.7622\n",
      "  - MAE:  5.5583 ± 7.0292\n",
      "  - Folds: 8\n",
      "Baseline CV:\n",
      "  - RMSE: 9.9348 ± 11.5728\n",
      "  - MAE:  7.9484 ± 9.5249\n",
      "  - Folds: 5\n",
      "\n",
      "Comparison:\n",
      "  - RMSE improvement: 37.83%\n",
      "  - MAE improvement: 30.07%\n",
      "  - Adaptive CV shows better performance!\n",
      "\n",
      "==================================================\n",
      "INDIVIDUAL LINEAR REGRESSION EXAMPLE\n",
      "==================================================\n",
      "Single Model Performance:\n",
      "  - RMSE: 30.7725\n",
      "  - MAE:  24.1734\n",
      "  - R²:   0.4396\n",
      "\n",
      "Model created successfully!\n",
      "Use .fit(X_train, y_train) to train and .predict(X_test) to predict\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, mannwhitneyu\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Preprocess data\n",
    "df = pd.read_csv(\"nvidia_10yr_data.csv\", parse_dates=[\"Date\"])\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=\"%d/%m/%Y\")\n",
    "df = df.sort_values(\"Date\")\n",
    "\n",
    "# Feature engineering\n",
    "df['Return'] = df['Close'].pct_change()\n",
    "df['Volatility'] = df['Close'].rolling(10).std()\n",
    "df['Price_Diff'] = df['High'] - df['Low']\n",
    "df['Volume_Log'] = np.log1p(df['Volume'])\n",
    "\n",
    "# Drop NaN หลัง rolling\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[['Return', 'Volatility', 'Price_Diff', 'Volume_Log']]\n",
    "y = df['Close']\n",
    "\n",
    "\n",
    "class LinearRegressionModel:\n",
    "    \"\"\"\n",
    "    Linear Regression model with standardization\n",
    "    \"\"\"\n",
    "    def __init__(self, fit_intercept: bool = True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.scaler_X = StandardScaler()\n",
    "        self.scaler_y = StandardScaler()\n",
    "        self.model = LinearRegression(fit_intercept=fit_intercept)\n",
    "        self.is_fitted = False\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        \"\"\"\n",
    "        Train Linear Regression model\n",
    "        \"\"\"\n",
    "        # Scale features\n",
    "        X_scaled = self.scaler_X.fit_transform(X)\n",
    "        y_scaled = self.scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(X_scaled, y_scaled)\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model not fitted yet\")\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler_X.transform(X)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_scaled = self.model.predict(X_scaled)\n",
    "        \n",
    "        # Inverse transform\n",
    "        y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "\n",
    "class DriftPointDetector:\n",
    "    \"\"\"\n",
    "    ตรวจจับจุดเกิด concept drift ในข้อมูล time series ด้วยการใช้\n",
    "    หลายวิธีทดสอบและป้องกันการจับ pattern ที่ผิดพลาด\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size: int = 120, threshold: float = 0.001, \n",
    "                 step_size: int = 30, min_effect_size: float = 0.3,\n",
    "                 stability_window: int = 60, confirmation_tests: int = 2):\n",
    "        self.window_size = window_size\n",
    "        self.threshold = threshold\n",
    "        self.step_size = step_size\n",
    "        self.min_effect_size = min_effect_size\n",
    "        self.stability_window = stability_window\n",
    "        self.confirmation_tests = confirmation_tests\n",
    "        self.drift_points_: List[int] = []\n",
    "\n",
    "    def _calculate_effect_size(self, window1: pd.Series, window2: pd.Series) -> float:\n",
    "        \"\"\"คำนวณขนาดผลกระทบ (Cohen's d)\"\"\"\n",
    "        mean1, mean2 = window1.mean(), window2.mean()\n",
    "        std1, std2 = window1.std(), window2.std()\n",
    "        \n",
    "        pooled_std = np.sqrt(((len(window1) - 1) * std1**2 + (len(window2) - 1) * std2**2) / \n",
    "                           (len(window1) + len(window2) - 2))\n",
    "        \n",
    "        if pooled_std == 0:\n",
    "            return 0\n",
    "        \n",
    "        return abs(mean1 - mean2) / pooled_std\n",
    "\n",
    "    def _test_multiple_statistics(self, window1: pd.DataFrame, window2: pd.DataFrame) -> Tuple[int, float]:\n",
    "        \"\"\"ทดสอบหลายวิธีเพื่อยืนยัน drift\"\"\"\n",
    "        passed_tests = 0\n",
    "        min_p_value = 1.0\n",
    "        \n",
    "        for col in window1.columns:\n",
    "            col_tests = 0\n",
    "            col_p_values = []\n",
    "            \n",
    "            # Test 1: Kolmogorov-Smirnov test\n",
    "            try:\n",
    "                stat, p_value = ks_2samp(window1[col], window2[col])\n",
    "                col_p_values.append(p_value)\n",
    "                if p_value < self.threshold:\n",
    "                    col_tests += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Test 2: Mann-Whitney U test\n",
    "            try:\n",
    "                stat, p_value = mannwhitneyu(window1[col], window2[col], alternative='two-sided')\n",
    "                col_p_values.append(p_value)\n",
    "                if p_value < self.threshold:\n",
    "                    col_tests += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Test 3: Effect size check\n",
    "            effect_size = self._calculate_effect_size(window1[col], window2[col])\n",
    "            if effect_size > self.min_effect_size:\n",
    "                col_tests += 1\n",
    "            \n",
    "            if col_p_values:\n",
    "                min_p_value = min(min_p_value, min(col_p_values))\n",
    "            \n",
    "            if col_tests >= self.confirmation_tests:\n",
    "                passed_tests += 1\n",
    "        \n",
    "        return passed_tests, min_p_value\n",
    "\n",
    "    def _check_stability_before_drift(self, X: pd.DataFrame, position: int) -> bool:\n",
    "        \"\"\"ตรวจสอบว่าช่วงก่อนหน้ามีเสถียรภาพหรือไม่\"\"\"\n",
    "        if position < self.stability_window + self.window_size:\n",
    "            return True\n",
    "        \n",
    "        stable_start = position - self.stability_window - self.window_size\n",
    "        stable_end = position - self.window_size\n",
    "        stable_window = X.iloc[stable_start:stable_end]\n",
    "        \n",
    "        mid_point = len(stable_window) // 2\n",
    "        stable_part1 = stable_window.iloc[:mid_point]\n",
    "        stable_part2 = stable_window.iloc[mid_point:]\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if len(stable_part1) > 0 and len(stable_part2) > 0:\n",
    "                try:\n",
    "                    stat, p_value = ks_2samp(stable_part1[col], stable_part2[col])\n",
    "                    if p_value < self.threshold * 10:\n",
    "                        return False\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _remove_pattern_drifts(self, drift_candidates: List[Tuple[int, float]]) -> List[int]:\n",
    "        \"\"\"กรองจุด drift ที่อาจเป็น pattern\"\"\"\n",
    "        if len(drift_candidates) < 3:\n",
    "            return [pos for pos, _ in drift_candidates]\n",
    "        \n",
    "        drift_candidates.sort(key=lambda x: x[0])\n",
    "        \n",
    "        intervals = []\n",
    "        for i in range(1, len(drift_candidates)):\n",
    "            interval = drift_candidates[i][0] - drift_candidates[i-1][0]\n",
    "            intervals.append(interval)\n",
    "        \n",
    "        filtered_drifts = []\n",
    "        if len(intervals) > 1:\n",
    "            interval_std = np.std(intervals)\n",
    "            interval_mean = np.mean(intervals)\n",
    "            \n",
    "            if interval_std / interval_mean < 0.3:\n",
    "                drift_candidates.sort(key=lambda x: x[1])\n",
    "                keep_count = max(1, len(drift_candidates) // 3)\n",
    "                filtered_drifts = [pos for pos, _ in drift_candidates[:keep_count]]\n",
    "            else:\n",
    "                filtered_drifts = [pos for pos, _ in drift_candidates]\n",
    "        else:\n",
    "            filtered_drifts = [pos for pos, _ in drift_candidates]\n",
    "        \n",
    "        final_drifts = []\n",
    "        min_distance = self.window_size * 2\n",
    "        \n",
    "        for pos in sorted(filtered_drifts):\n",
    "            if not final_drifts or pos - final_drifts[-1] >= min_distance:\n",
    "                final_drifts.append(pos)\n",
    "        \n",
    "        return final_drifts\n",
    "\n",
    "    def detect(self, X: pd.DataFrame) -> List[int]:\n",
    "        self.drift_points_ = []\n",
    "        n = len(X)\n",
    "        drift_candidates = []\n",
    "        \n",
    "        for i in range(self.window_size, n - self.window_size, self.step_size):\n",
    "            if not self._check_stability_before_drift(X, i):\n",
    "                continue\n",
    "            \n",
    "            window1 = X.iloc[i - self.window_size:i]\n",
    "            window2 = X.iloc[i:i + self.window_size]\n",
    "            \n",
    "            passed_tests, min_p_value = self._test_multiple_statistics(window1, window2)\n",
    "            \n",
    "            if passed_tests >= 1:\n",
    "                drift_candidates.append((i, min_p_value))\n",
    "        \n",
    "        self.drift_points_ = self._remove_pattern_drifts(drift_candidates)\n",
    "        \n",
    "        return self.drift_points_\n",
    "\n",
    "\n",
    "class AdaptiveFoldGenerator:\n",
    "    \"\"\"\n",
    "    สร้าง train/test folds โดยแบ่งตาม drift points ที่ตรวจจับได้\n",
    "    \"\"\"\n",
    "    def __init__(self, min_fold_size: int = 200, test_ratio: float = 0.2):\n",
    "        self.min_fold_size = min_fold_size\n",
    "        self.test_ratio = test_ratio\n",
    "\n",
    "    def split(self, X: pd.DataFrame, drift_points: List[int]) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        folds = []\n",
    "        points = [0] + drift_points + [len(X)]\n",
    "        \n",
    "        for i in range(len(points) - 1):\n",
    "            start, end = points[i], points[i + 1]\n",
    "            fold_length = end - start\n",
    "\n",
    "            if fold_length < self.min_fold_size:\n",
    "                continue\n",
    "\n",
    "            split = int(start + (1 - self.test_ratio) * fold_length)\n",
    "            train_idx = np.arange(start, split)\n",
    "            test_idx = np.arange(split, end)\n",
    "\n",
    "            # เพิ่มขนาดขั้นต่ำ\n",
    "            if len(train_idx) > 50 and len(test_idx) > 20:\n",
    "                folds.append((train_idx, test_idx))\n",
    "        \n",
    "        return folds\n",
    "\n",
    "\n",
    "class DriftAdaptiveTimeSeriesCV:\n",
    "    \"\"\"\n",
    "    ทำ cross-validation โดยใช้ fold ที่แบ่งตาม drift points สำหรับ Linear Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, model_params: dict = None):\n",
    "        self.model_params = model_params or {'fit_intercept': True}\n",
    "\n",
    "    def run(self, X: pd.DataFrame, y: pd.Series, drift_points: List[int]) -> Tuple[List[float], List[float]]:\n",
    "        fold_gen = AdaptiveFoldGenerator()\n",
    "        metrics_rmse, metrics_mae = [], []\n",
    "\n",
    "        folds = fold_gen.split(X, drift_points)\n",
    "        if not folds:\n",
    "            print(\"Warning: No valid folds generated by AdaptiveFoldGenerator!\")\n",
    "            return [], []\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(folds):\n",
    "            print(f\"\\n[Adaptive Fold {i+1}] Training Linear Regression...\")\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # สร้างโมเดล Linear Regression ใหม่สำหรับแต่ละ fold\n",
    "            model = LinearRegressionModel(**self.model_params)\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                \n",
    "                print(f\"[Adaptive Fold {i+1}] RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "                \n",
    "                metrics_rmse.append(rmse)\n",
    "                metrics_mae.append(mae)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Adaptive Fold {i+1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return metrics_rmse, metrics_mae\n",
    "\n",
    "\n",
    "class BaselineTimeSeriesCV:\n",
    "    \"\"\"\n",
    "    ทำ cross-validation แบบ TimeSeriesSplit ปกติ สำหรับ Linear Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, model_params: dict = None, n_splits: int = 5):\n",
    "        self.model_params = model_params or {'fit_intercept': True}\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def run(self, X: pd.DataFrame, y: pd.Series) -> Tuple[List[float], List[float]]:\n",
    "        tscv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "        metrics_rmse, metrics_mae = [], []\n",
    "\n",
    "        for i, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "            print(f\"\\n[Baseline Fold {i+1}] Training Linear Regression...\")\n",
    "            \n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # สร้างโมเดล Linear Regression ใหม่สำหรับแต่ละ fold\n",
    "            model = LinearRegressionModel(**self.model_params)\n",
    "            \n",
    "            try:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "                \n",
    "                print(f\"[Baseline Fold {i+1}] RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
    "                \n",
    "                metrics_rmse.append(rmse)\n",
    "                metrics_mae.append(mae)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"[Baseline Fold {i+1}] Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        return metrics_rmse, metrics_mae\n",
    "\n",
    "\n",
    "class LinearRegressionAnalysis:\n",
    "    \"\"\"\n",
    "    วิเคราะห์ประสิทธิภาพของ Linear Regression\n",
    "    \"\"\"\n",
    "    def __init__(self, model_params: dict = None):\n",
    "        self.model_params = model_params or {'fit_intercept': True}\n",
    "        \n",
    "    def analyze(self, X: pd.DataFrame, y: pd.Series, drift_points: List[int]):\n",
    "        \"\"\"\n",
    "        วิเคราะห์ Linear Regression ด้วย adaptive CV\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Linear Regression Analysis\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Adaptive CV\n",
    "        drift_cv = DriftAdaptiveTimeSeriesCV(self.model_params)\n",
    "        drift_rmse, drift_mae = drift_cv.run(X, y, drift_points)\n",
    "        \n",
    "        # Baseline CV\n",
    "        baseline_cv = BaselineTimeSeriesCV(self.model_params, n_splits=5)\n",
    "        base_rmse, base_mae = baseline_cv.run(X, y)\n",
    "        \n",
    "        results = {\n",
    "            'adaptive_rmse': drift_rmse,\n",
    "            'adaptive_mae': drift_mae,\n",
    "            'baseline_rmse': base_rmse,\n",
    "            'baseline_mae': base_mae\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_summary(self, results: dict):\n",
    "        \"\"\"\n",
    "        พิมพ์สรุปผลลัพธ์\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"LINEAR REGRESSION ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        print(f\"\\nLinear Regression Results:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Adaptive results\n",
    "        if results['adaptive_rmse'] and results['adaptive_mae']:\n",
    "            avg_rmse = np.mean(results['adaptive_rmse'])\n",
    "            avg_mae = np.mean(results['adaptive_mae'])\n",
    "            std_rmse = np.std(results['adaptive_rmse'])\n",
    "            std_mae = np.std(results['adaptive_mae'])\n",
    "            print(f\"Adaptive CV:\")\n",
    "            print(f\"  - RMSE: {avg_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "            print(f\"  - MAE:  {avg_mae:.4f} ± {std_mae:.4f}\")\n",
    "            print(f\"  - Folds: {len(results['adaptive_rmse'])}\")\n",
    "        else:\n",
    "            print(\"Adaptive CV - No valid results\")\n",
    "        \n",
    "        # Baseline results\n",
    "        if results['baseline_rmse'] and results['baseline_mae']:\n",
    "            avg_rmse = np.mean(results['baseline_rmse'])\n",
    "            avg_mae = np.mean(results['baseline_mae'])\n",
    "            std_rmse = np.std(results['baseline_rmse'])\n",
    "            std_mae = np.std(results['baseline_mae'])\n",
    "            print(f\"Baseline CV:\")\n",
    "            print(f\"  - RMSE: {avg_rmse:.4f} ± {std_rmse:.4f}\")\n",
    "            print(f\"  - MAE:  {avg_mae:.4f} ± {std_mae:.4f}\")\n",
    "            print(f\"  - Folds: {len(results['baseline_rmse'])}\")\n",
    "        else:\n",
    "            print(\"Baseline CV - No valid results\")\n",
    "        \n",
    "        # เปรียบเทียบ\n",
    "        if (results['adaptive_rmse'] and results['adaptive_mae'] and \n",
    "            results['baseline_rmse'] and results['baseline_mae']):\n",
    "            \n",
    "            adaptive_avg_rmse = np.mean(results['adaptive_rmse'])\n",
    "            baseline_avg_rmse = np.mean(results['baseline_rmse'])\n",
    "            \n",
    "            adaptive_avg_mae = np.mean(results['adaptive_mae'])\n",
    "            baseline_avg_mae = np.mean(results['baseline_mae'])\n",
    "            \n",
    "            print(f\"\\nComparison:\")\n",
    "            print(f\"  - RMSE improvement: {((baseline_avg_rmse - adaptive_avg_rmse) / baseline_avg_rmse * 100):.2f}%\")\n",
    "            print(f\"  - MAE improvement: {((baseline_avg_mae - adaptive_avg_mae) / baseline_avg_mae * 100):.2f}%\")\n",
    "            \n",
    "            if adaptive_avg_rmse < baseline_avg_rmse:\n",
    "                print(\"  - Adaptive CV shows better performance!\")\n",
    "            else:\n",
    "                print(\"  - Baseline CV shows better performance!\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# ตัวอย่างการใช้งาน\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Detect drift points\n",
    "    detector = DriftPointDetector(\n",
    "        window_size=120, \n",
    "        threshold=0.001, \n",
    "        step_size=30,\n",
    "        min_effect_size=0.3,\n",
    "        stability_window=60,\n",
    "        confirmation_tests=2\n",
    "    )\n",
    "    drift_points = detector.detect(X)\n",
    "    print(f\"Detected drift points at indices: {drift_points}\")\n",
    "    print(f\"Total drift points found: {len(drift_points)}\")\n",
    "\n",
    "    # 2) วิเคราะห์ Linear Regression\n",
    "    model_params = {'fit_intercept': True}\n",
    "    \n",
    "    analyzer = LinearRegressionAnalysis(model_params)\n",
    "    results = analyzer.analyze(X, y, drift_points)\n",
    "    analyzer.print_summary(results)\n",
    "    \n",
    "    # 3) ตัวอย่างการใช้โมเดล Linear Regression แยกกัน\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INDIVIDUAL LINEAR REGRESSION EXAMPLE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # แบ่งข้อมูลเป็น train/test\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    \n",
    "    # สร้างและเทรนโมเดล\n",
    "    model = LinearRegressionModel(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # ทำนาย\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # คำนวณ metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Single Model Performance:\")\n",
    "    print(f\"  - RMSE: {rmse:.4f}\")\n",
    "    print(f\"  - MAE:  {mae:.4f}\")\n",
    "    print(f\"  - R²:   {r2:.4f}\")\n",
    "    \n",
    "    print(\"\\nModel created successfully!\")\n",
    "    print(\"Use .fit(X_train, y_train) to train and .predict(X_test) to predict\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
